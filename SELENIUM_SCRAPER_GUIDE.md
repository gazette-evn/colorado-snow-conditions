# Colorado Ski Scraper - Complete Guide

## ğŸ‰ What We Built

A **completely FREE** Selenium-based scraper that:
- âœ… Gets all **28 Colorado ski resorts** automatically
- âœ… Runs on **GitHub Actions** (cloud-hosted, no local computer needed)
- âœ… Updates every **2-4 hours** during ski season
- âœ… Feeds Datawrapper maps & tables
- âœ… **$0 ongoing cost**

---

## ğŸ“ New Files Created

### Core Scraper Files

1. **`colorado_ski_scraper.py`** - Selenium scraper  
   - Uses headless Chrome to load the page
   - Waits for JavaScript to render
   - Extracts resort data from HTML
   - Multiple parsing strategies (table, divs, data attributes)

2. **`colorado_data_fetcher.py`** - Data processor
   - Integrates scraper with pipeline
   - Adds coordinates (lat/lng) to resorts
   - Standardizes data format
   - Calculates derived fields (status, percentages)

3. **`test_scraper.sh`** - Test script  
   - Quick local testing
   - Checks Chrome installation
   - Runs scraper and shows results

### Updated Files

4. **`requirements.txt`** - Added Selenium & BeautifulSoup
5. **`.github/workflows/update-snow-data.yml`** - Chrome installation for CI

---

## ğŸš€ How It Works

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         GitHub Actions (Every 2 hours)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Spin up Ubuntu VM with Chrome installed     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. colorado_ski_scraper.py                     â”‚
â”‚     - Launch headless Chrome                    â”‚
â”‚     - Load coloradoski.com/snow-report          â”‚
â”‚     - Wait for JavaScript to render data        â”‚
â”‚     - Parse HTML for 28 resort conditions       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. colorado_data_fetcher.py                    â”‚
â”‚     - Add coordinates to each resort            â”‚
â”‚     - Calculate status (Open/Closed/Limited)    â”‚
â”‚     - Format for Datawrapper                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. snow_map.py & snow_table.py                 â”‚
â”‚     - Update Datawrapper visualizations         â”‚
â”‚     - Publish live map & table                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ Data Collected

For each of the **28 Colorado resorts**:

- âœ… **Resort name**
- âœ… **24-hour new snow** (inches)
- âœ… **Trails open/total** (e.g., "5/147")
- âœ… **Conditions** (Man made, Closed, etc.)
- âœ… **Status** (Open, Closed, Limited) - calculated
- âœ… **Coordinates** (lat/lng) - for mapping
- âœ… **Timestamp** - when data was fetched

---

## ğŸ§ª Testing Locally

### Prerequisites

1. **Google Chrome** installed
   ```bash
   # macOS
   brew install --cask google-chrome
   
   # Ubuntu/Linux
   # See GitHub Actions workflow for commands
   ```

2. **Python packages**
   ```bash
   pip install -r requirements.txt
   ```

### Run Tests

```bash
# Option 1: Use test script (easiest)
./test_scraper.sh

# Option 2: Run scraper directly
python colorado_ski_scraper.py

# Option 3: Run full data fetcher
python colorado_data_fetcher.py
```

### Expected Output

```
âœ… Chrome driver initialized successfully
âœ… Page body loaded
âœ… Retrieved HTML
âœ… Extracted 28 resorts
âœ… Cleaned data for 28 resorts
âœ… Chrome driver closed
âœ… Saved data to colorado_resorts_scraped.csv
```

---

## â˜ï¸ GitHub Actions Setup

### Current Configuration

**File:** `.github/workflows/update-snow-data.yml`

**Schedule:** Every 2 hours  
```yaml
schedule:
  - cron: '0 */2 * * *'
```

**What it does:**
1. Checks out code
2. Installs Python 3.11
3. Installs dependencies
4. **Installs Chrome** (for Selenium)
5. Runs scraper
6. Updates Datawrapper
7. Uploads logs

### Free Tier Limits

- **2,000 minutes/month** free on GitHub Actions
- Each run takes ~3-5 minutes
- 12 runs/day Ã— 30 days = 360 runs = ~1,800 minutes
- **Well within free tier!** âœ…

---

## ğŸ”§ Customization

### Adjust Update Frequency

Edit `.github/workflows/update-snow-data.yml`:

```yaml
# Every 2 hours (current)
- cron: '0 */2 * * *'

# Every 4 hours
- cron: '0 */4 * * *'

# Every hour (aggressive)
- cron: '0 * * * *'

# 3 times daily (6am, 2pm, 10pm)
- cron: '0 6,14,22 * * *'
```

### Add More Resorts

If the scraper finds new resorts not in the coordinates list:

1. Check `colorado_scraper.log` for warnings
2. Add coordinates to `RESORT_COORDINATES` in `colorado_data_fetcher.py`
3. Commit and push

### Debugging

If scraping fails:

1. **Check logs:** `colorado_scraper.log`
2. **Inspect HTML:** `colorado_ski_page_rendered.html`
3. **Verify selectors:** Page structure may have changed
4. **Update parsing logic** in `colorado_ski_scraper.py`

---

## ğŸ› Troubleshooting

### "No resort data found"

**Cause:** Page structure changed  
**Fix:** 
1. Check `colorado_ski_page_rendered.html`
2. Update parsing logic in `_extract_resort_from_*` methods
3. May need to adjust wait times or selectors

### "Chrome driver failed"

**Cause:** Chrome not installed or incompatible  
**Fix:**
- Local: Install Chrome
- GitHub Actions: Already handled in workflow

### "Missing coordinates for X resorts"

**Cause:** New resorts or name mismatch  
**Fix:** Add to `RESORT_COORDINATES` dictionary

---

## ğŸ’° Cost Analysis

### Current Setup (FREE)
- GitHub Actions: **$0** (within free tier)
- Selenium: **$0** (open source)
- Chrome: **$0** (free browser)
- BeautifulSoup: **$0** (open source)
- **Total: $0/month**

### Alternative (SnoCountry API)
- Cost: **$2,150/year** ($179/month)
- Benefit: Professional, zero maintenance
- When to consider: If scraper becomes unreliable

---

## ğŸ”„ Maintenance

### Expected Maintenance

**Low:** ~1-2 hours every 3-6 months

**When needed:**
- Colorado Ski Country USA changes their website
- Update parsing logic to match new HTML structure
- Usually just adjusting CSS selectors or data attributes

**How to fix:**
1. Run scraper locally
2. Check `colorado_ski_page_rendered.html`
3. Update parsing methods
4. Test and commit

---

## âœ… Next Steps

### To Go Live:

1. **Create Datawrapper Charts** (if not done)
   - Map: Locator map of Colorado
   - Table: Sortable resort data

2. **Add Chart IDs to `.env`**
   ```bash
   SNOW_MAP_CHART_ID=your_map_id
   SNOW_TABLE_CHART_ID=your_table_id
   ```

3. **Update `snow_map.py` and `snow_table.py`**
   - Replace RapidAPI fetcher with colorado_data_fetcher
   - (I can do this next!)

4. **Push to GitHub**
   ```bash
   git add .
   git commit -m "Add Selenium scraper for Colorado resorts"
   git push
   ```

5. **Add GitHub Secrets**
   - DATAWRAPPER_API_KEY (already have)
   - SNOW_MAP_CHART_ID
   - SNOW_TABLE_CHART_ID

6. **Test GitHub Action**
   - Actions tab â†’ Run workflow manually
   - Check logs
   - Verify Datawrapper updates

---

## ğŸ¯ Success Metrics

**You'll know it's working when:**
- âœ… GitHub Actions runs every 2 hours (no failures)
- âœ… Logs show "28 resorts" scraped
- âœ… Datawrapper map shows all resort markers
- âœ… Datawrapper table updates with current data
- âœ… Resorts that open (like Keystone, A-Basin) show correct status

---

## ğŸ“ Support

**If something breaks:**

1. Check GitHub Actions logs
2. Download log artifacts
3. Look for specific error messages
4. Check if Colorado Ski Country site changed
5. Update parsing logic as needed

**Common fixes take 15-30 minutes once you know what changed!**

---

## ğŸ¿ Summary

You now have a **production-ready, completely free** scraper that:
- Works 100% in the cloud (GitHub Actions)
- Gets all 28 Colorado resorts
- Updates automatically every 2 hours
- Costs $0 forever
- Maintainable (1-2 hours every few months)

**Much better than paying $2,150/year!** ğŸ‰

